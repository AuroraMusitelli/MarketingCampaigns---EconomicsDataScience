---
title: 'ELABORATO: DATA MINING'
author: "Giorgia Gossi, Aurora Musitelli, Chiara Zani"
date: "4/1/2022"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**ELABORATO 2: DATA MINING**
Orange Telecom e' la maggiore impresa di telecomunicazioni in Francia. Con  170.000 dipendenti e 230,7 milioni di clienti nel mondo, e' una delle principali aziende mondiali del settore. ? presente, oltre che in Francia, in molti altri paesi del mondo tra cui Marocco, Regno Unito, Spagna, Polonia, Egitto, Romania, Moldavia, Belgio, Slovacchia e nelle ex-colonie francesi. Vediamo pi? da vicino di cosa si occupa esattamente l'operatore telefonico Orange. In particolare, le sue attivit? sono:
.	la telefonia fissa, Internet, telefonia IP, videotelefonia, televisione digitale con "Orange TV" e contenuti multimediali;
.	la telefonia mobile;
.	i servizi di comunicazione aziendale (con il marchio Orange Business Services).
**L'obiettivo** ? quello di prevedere il comportamento per fidelizzare i clienti della compagnia telefonica  Orange Telecom. 




carichiamo i dataset gi? suddivisi tra training e validation 
```{r}
training <- read.csv('churn-bigml-80.csv', sep=',', dec=',')
validation <- read.csv('churn-bigml-20.csv', sep=',', dec=',')
str(training)
str(validation)
```

UNIRE I DS
```{r}
ds<-rbind(training, validation)
str(ds)
```


```{r}
#controlliamo le variabili sui dati di training
library(funModeling)
library(dplyr)
statusT=df_status(training, print_results = F)
```



```{r, include=FALSE}
#controlliamo le variabili sui dati di validation
library(funModeling)
library(dplyr)
statusV=df_status(validation, print_results = F)
```




```{r, include=FALSE}
#cambiamo la tipologia delle variabili dopo averle osservate precedentemente
ds$Total.day.minutes<-as.numeric(ds$Total.day.minutes)
ds$Total.day.charge<-as.numeric(ds$Total.day.charge)
ds$Total.eve.minutes<-as.numeric(ds$Total.eve.minutes)
ds$Total.eve.charge<-as.numeric(ds$Total.eve.charge)
ds$Total.night.minutes<-as.numeric(ds$Total.night.minutes)
ds$Total.night.charge<-as.numeric(ds$Total.night.charge)
ds$ Total.intl.minutes<-as.numeric(ds$ Total.intl.minutes)
ds$ Total.intl.charge<-as.numeric(ds$ Total.intl.charge)
```



controlliamo
```{r}
str(ds)
```




**1. Distribuzione della variabile target y: ? realistica dal punto di vista interpretativo? se si proseguo, se no bilancio  le prior e devo aggiustare poi le posterior nello STEP2**
```{r}
#distribuzione della variabile target Churn
table(ds$Churn)/nrow(ds)
table(ds$Churn)
```
**distribuzione della variabile target realistica**, ossia l'85% (2278 soggetti) dei clienti non lascia la compagnia Orange telecom mentre il 14% (388 soggetti) dei clienti lascia la compagnia Orange Telecom, quindi possiamo preseguire e non bilanciare le prior!! (? un bene che i clienti non abbandonano la compagnia telefonica)






**2. Quale metrica ? importante nella tabella di confusione? ci sono costi?**

matrice di costi e profitti: costa di pi√π classificare come sleale( churn, 'True') un cliente leale(non churn, 'False')
```{r}
costmat <- as.data.frame(matrix(nrow = 2, ncol = 2))
costmat[1,1] <-  10 
costmat[1,2] <- -100
costmat[2,1] <- -5
costmat[2,2] <-  1
colnames(costmat)<-c('False_pred', 'True_pred')
rownames(costmat)<-c('False_obs', 'True_obs')
costmat
```

funzione che calcola il profitto come metrica
```{r}
f1 <- function(data, lev = NULL, model = NULL) {
  risul <- confusionMatrix(data$pred, data$obs)
  confmat <- risul$table
  f1_val <- costmat[1,1] * confmat[1,1] + costmat[1,2] * confmat[1,2] + costmat[2,1] * confmat[2,1] + costmat[2,2] * confmat[2,2]
  c(F1 = f1_val)
}
```






**PREPROCESSING**


#### collin, nzv, na imputation ####

1.COLLINEARITA
creiamo un modello logistico e osserviamo la correlazione tra le variabili numeriche
```{r, include=FALSE}
ds$Churn<-as.factor(ds$Churn)
modLogis <- glm(Churn ~ ., ds, family='binomial')
ls(modLogis)
modLogis$terms
cov_numeric=attr(terms(modLogis), "term.labels") 
cov_numeric
```

```{r}
library(dplyr)
data_numeric <- ds[,cov_numeric] %>% dplyr::select_if(is.numeric)
```

```{r}
library(PerformanceAnalytics)
chart.Correlation(data_numeric , histogram=TRUE, pch=22)
```

covariate correlate attraverso la libreria caret
```{r}
library(caret)
R=cor(data_numeric)

correlatedPredictors = findCorrelation(R, cutoff = 0.95, names = TRUE)
correlatedPredictors
```
risultano correlate tra di loro le seguenti covariate (sensato poich? in base al numero di chiamate che vengono effettuate durante la giornata questo ha un impatto diretto sul fatturato e viceversa):

"Total.day.minutes" e "Total.day.charge" = cor 0.999
"Total.intl.charge" e "Total.intl.minutes" = cor 0.999
"Total.eve.charge" e "Total.eve.minutes" = cor 0.999   
"Total.night.charge" e "Total.night.minutes" = cor 0.999




2.COVARIATE CON VARIANZA ZERO (zeroVar) E VARIANZA VICINO A ZERO (nzv)
```{r}
nzv = nearZeroVar(training, saveMetrics = TRUE)
nzv    
```
Number vmail messages near zero variance
Possiamo vedere sopra che se chiamiamo la funzione nearZeroVar con l'argomento saveMetrics = TRUE abbiamo accesso al rapporto di frequenza e alla percentuale di valori univoci per ogni predittore. Per impostazione predefinita, un predittore ? classificato come varianza prossima allo zero se la percentuale di valori univoci nei campioni ? inferiore a {10\%}. 



3.VALORI MANCANTI
```{r}
sapply(ds, function(x)(sum(is.na(x))))  #conteggio dei valori mancanti
```
il dataset non presenta nessun valore mancante 


4.Altre strategie di preprocessing sono lo SCALING che facciamo durante il tuning dei modelli che lo richiedono






Suddividiamo il dataset in training validation e score
```{r}
#### divide score dataset####
library(caret)
set.seed(1234)
split <- createDataPartition(y=ds$Churn, p = 0.3, list = FALSE)
validation <- ds[split,]
train <- ds[-split,]
split1 <- createDataPartition(y=validation$Churn, p = 0.1, list = FALSE)
score <- validation[split1,]
validation <- validation[-split1,]
```
adesso il dataset da utilizzare e' 'train' (inteso come training)






**STEP1:** build models (decide models, preprocessing, tuning, model selection)
1.1 per ogni modello che richiede MODEL-SELECTION, farlo prima di tunare i modelli con caret
# selezioniamo le covariate piu' importanti con tree #


prima cambiamo churn da int a factor (con due livelli del target) per i passaggi successivi
```{r}
train$Churn<-as.factor(train$Churn)
str(train)
```

 


## TREE ##
```{r}
library(caret)
set.seed(1)
metric <- "F1"
cvCtrl <- trainControl(method = "cv", number=10, search="grid", classProbs = TRUE,
                       summaryFunction = f1)
Tree <- train(Churn ~ ., data = train, method = "rpart",
                      tuneLength = 10, metric=metric,
                      trControl = cvCtrl)
Tree
getTrainPerf(Tree)
plot(Tree)
confusionMatrix(Tree)
```




```{r}
# var imp of the tree
varImp(object=Tree)
plot(varImp(object=Tree), main="train tuned - Variable Importance")
```


```{r}
#object saved
ls(Tree)
ls(Tree$finalModel)
```



```{r}
# select only important variables
vi=as.data.frame(Tree$finalModel$variable.importance)
viname=row.names(vi)
viname
```


```{r}
# select most important var from a tree 
list=c("Total.day.charge",      "Total.day.minutes" ,     "Total.eve.charge" ,      "Total.eve.minutes" ,    
 "Customer.service.calls", "Total.intl.minutes",     "Total.intl.charge" ,     "International.plan" ,
  "Total.intl.calls" ,      "Total.night.minutes" ,   "Number.vmail.messages" , "Voice.mail.plan",    
"Total.night.charge" ,    "Total.day.calls" ,       "Total.night.calls" ,     "Account.length" ,       
 "Area.code"  ,            "Total.eve.calls" ,       "State")
```


Abbiamo aspettato a risolvere la collinearit per vedere se la model selection dell'albero la risolvesse. Ma non l'ha fatto, quindi abbiamo tolto le variabili minutes che erano collineari. Abbiamo tolto anche number vmail messages che presentava near zero variance
```{r}
# select most important var from a tree 
list=c("Total.day.charge" ,     "Total.eve.charge" ,    
 "Customer.service.calls",     "Total.intl.charge" ,     "International.plan" ,
  "Total.intl.calls"  , "Voice.mail.plan",    
"Total.night.charge" ,    "Total.day.calls" ,       "Total.night.calls" ,     "Account.length" ,       
 "Area.code"  ,            "Total.eve.calls" ,       "State")
```



```{r}
train2=train[,list]
validation2=validation[,list]
validation2=cbind(validation$Churn, validation2)
names(validation2)[1] <- 'Churn'
```




## RANDOM FOREST ##
```{r}
library(caret)
set.seed(1)
ctrl =trainControl(method="cv", number = 10, classProbs = T,
                   summaryFunction=f1)
rfTune <- train(Churn ~ ., data = train, method = "rf",
                tuneLength = 10, metric=metric,
                trControl = ctrl)
rfTune
```

```{r}
confusionMatrix(rfTune)
```


```{r}
# permutation importance
vimp=varImp(rfTune)
plot(varImp(object=rfTune),main="train tuned - Variable Importance")
vimp=data.frame(vimp[1])
vimp$var=row.names(vimp)
head(vimp)
```

```{r}
row.names(vimp) 
```

```{r}
list2=c( "Account.length" ,        "International.plan" , "Voice.mail.plan" ,   "Number.vmail.messages" ,
 "Total.day.minutes" ,     "Total.day.calls"    ,    "Total.day.charge"    ,   "Total.eve.minutes" ,    
  "Total.eve.calls"  ,      "Total.eve.charge"   ,    "Total.night.minutes"  ,  "Total.night.calls"  ,   
"Total.night.charge"  ,   "Total.intl.minutes"   ,  "Total.intl.calls"  ,     "Total.intl.charge"    , 
 "Customer.service.calls")
```

Abbiamo tolto le var collineari e quella con nzv
```{r}
list2=c( "Account.length" ,        "International.plan" , "Voice.mail.plan"  ,     "Total.day.calls"    ,    "Total.day.charge"    ,    
  "Total.eve.calls"  ,      "Total.eve.charge"   ,      "Total.night.calls"  ,   
"Total.night.charge"  ,   "Total.intl.minutes"   ,  "Total.intl.calls"  ,     "Total.intl.charge"    , 
 "Customer.service.calls")
```

```{r}
# select covariate with imp>15% than most important
vimp2=vimp[vimp$Overall>15,]
head(vimp2)

train3=train[,list2]
train3=cbind(train$Churn, train3)
names(train3)[1] <- "Churn"

validation3=validation[,list2]
validation3=cbind(validation$Churn, validation3)
names(validation3)[1] <- "Churn"
```

Unisco la colonna churn al training con la model selection dell'albero
```{r}
train2<-cbind(train$Churn, train2)
names(train2)[1] <- 'Churn'
```



## GLM BASE PRE PROCESSATO ##
```{r}
set.seed(1)
ctrl =trainControl(method="cv", number = 10, classProbs = T,
                   summaryFunction=f1)
glm=train(Churn~.,
          data=train2,method = "glm", metric= metric,
          trControl = ctrl, tuneLength=10, trace=TRUE, na.action = na.pass)
glm

table(train2$Churn)
confusionMatrix(glm)
```




## K-NEAREST NEIGHTBOUR ##
```{r}
set.seed(1)
ctrl =trainControl(method="cv", number = 10, classProbs = T,
                   summaryFunction=f1)
grid = expand.grid(k=seq(5,20,3))
knn=train(Churn~.,
          data=train2,method = "knn",
          trControl = ctrl, tuneLength=10, na.action = na.pass, metric=metric,
          tuneGrid=grid, preProcess=c("scale","corr"))
knn
plot(knn)
confusionMatrix(knn)
```




## LASSO ##
```{r}
set.seed(1)
ctrl =trainControl(method="cv", number = 10, classProbs = T,
                   summaryFunction=f1)
grid = expand.grid(.alpha=1,.lambda=seq(0, 1, by = 0.01))
lasso=train(Churn~.,
            data=train2,method = "glmnet",
            trControl = ctrl, tuneLength=10, na.action = na.pass, metric=metric,
            tuneGrid=grid)
lasso
plot(lasso)
confusionMatrix(lasso)
```






## NAIVE BAYES ##
```{r}
set.seed(1)
ctrl =trainControl(method="cv", number = 10, classProbs = T,
                   summaryFunction=f1)
naivebayes=train(Churn~.,
                 data=train2,method = "naive_bayes", metric=metric,
                 trControl = ctrl, tuneLength=10, na.action = na.pass) 
naivebayes
confusionMatrix(naivebayes)

```



## PLS regression ##
```{r}
library(pls)
set.seed(1234)
Control=trainControl(method= "cv",number=10, classProbs=TRUE,
                     summaryFunction=f1)
pls=train(Churn~. , data=train2 , method = "pls", metric=metric,
          trControl = Control, tuneLength=10)
pls
plot(pls)
confusionMatrix(pls)
```


## RETE NEURALE ##
```{r}
ctrl = trainControl(method="cv", number=10, summaryFunction = f1, classProbs = TRUE)
nnetFit_CV <- train(Churn~. , data=train3 ,
                    method = "nnet", 
                    tuneLength = 10, metric=metric, trControl=ctrl,
                    trace = FALSE,
                    maxit = 100)
nnetFit_CV
plot(nnetFit_CV)
confusionMatrix(nnetFit_CV)
```







**STEP 2**Assesment
#######################################################################################
#######################################################################################




MODELLI STIMATI:

1 - rfTune                             
2 - Tree                             
3 - lasso                         
4 - glm                            
5 - knn                             
6 - naivebayes                             
7 - pls                             
8 - nnetFit_CV  


Per ogni modello stimo gli EPi(churn) e EPi(non churn), se il profitto di classificare un'unit come churn e' maggiore di quello di classificarla come non churn allora sar√ classificata come churn
``````{r, echo=FALSE}
#---------step 2----------------------------------------------------------

#1 modello rfTune #####
costmat
predProb <-  predict(rfTune,  validation, type = "prob")[,1] #probabilita' prevista di essere non churn (False)
                     
EP_churn  = (1-predProb)*costmat[2,2] + predProb*costmat[1,2]  
EP_nchurn = predProb*costmat[1,1] + (1-predProb)*costmat[2,1]

decision = ifelse(EP_churn > EP_nchurn, 'True','False')

decision_table = table(validation$Churn,decision)
decision_table

# total profit of the previous model is sum of profit values weighted by elements of the confusion matrix
total_profit_model_rf = (decision_table[1,1]*costmat[1,1]+decision_table[2,1]*costmat[2,1]+decision_table[1,2]*costmat[1,2]+decision_table[2,2]*costmat[2,2]) #aggiorna
total_cost_model_rf   = -total_profit_model_rf

# mean profit is the mean 
mean_profit_model_rf = total_profit_model_rf/ nrow(validation) #aggiorna
mean_cost_model_rf   = -mean_profit_model_rf #cost expected mean
```

``````{r, echo=FALSE}
#2 modello Tree #####

predProb <-  predict(Tree,  validation, type = "prob")[,1]
#aggiorna
EP_churn  = (1-predProb)*costmat[2,2] + predProb*costmat[1,2]  
EP_nchurn = predProb*costmat[1,1] + (1-predProb)*costmat[2,1]

decision = ifelse(EP_churn > EP_nchurn, 'True','False')

decision_table = table(validation$Churn,decision)
decision_table

# total profit of the previous model is sum of profit values weighted by elements of the confusion matrix
total_profit_tree = (decision_table[1,1]*costmat[1,1]+decision_table[2,1]*costmat[2,1]+decision_table[1,2]*costmat[1,2]+decision_table[2,2]*costmat[2,2])
total_cost_tree   = -total_profit_tree

# mean profit is the mean 
mean_profit_tree = total_profit_tree/ nrow(validation) #aggiorna
mean_cost_tree   = -mean_profit_tree #cost expected mean
```

``````{r, echo=FALSE}
#3 modello lasso #####

predProb <-  predict(lasso,  validation2, type = "prob")[,1]
#aggiorna
EP_churn  = (1-predProb)*costmat[2,2] + predProb*costmat[1,2]  
EP_nchurn = predProb*costmat[1,1] + (1-predProb)*costmat[2,1]

decision = ifelse(EP_churn > EP_nchurn, 'True','False')

decision_table = table(validation2$Churn,decision)
decision_table

# total profit of the previous model is sum of profit values weighted by elements of the confusion matrix
total_profit_lasso = (decision_table[1,1]*costmat[1,1]+decision_table[2,1]*costmat[2,1]+decision_table[1,2]*costmat[1,2]+decision_table[2,2]*costmat[2,2]) #aggiorna da fare
total_cost_lasso   = -total_profit_lasso

# mean profit is the mean 
mean_profit_lasso = total_profit_lasso/ nrow(validation2) #aggiorna
mean_cost_lasso   = -mean_profit_lasso #cost expected mean
```

``````{r, echo=FALSE}
#4 modello glm #####

predProb <-  predict(glm,  validation2, type = "prob")[,1]
#aggiorna
EP_churn  = (1-predProb)*costmat[2,2] + predProb*costmat[1,2]  
EP_nchurn = predProb*costmat[1,1] + (1-predProb)*costmat[2,1]

decision = ifelse(EP_churn > EP_nchurn, 'True','False')

decision_table = table(validation2$Churn,decision)
decision_table

# total profit of the previous model is sum of profit values weighted by elements of the confusion matrix
total_profit_glm = (decision_table[1,1]*costmat[1,1]+decision_table[2,1]*costmat[2,1]+decision_table[1,2]*costmat[1,2]+decision_table[2,2]*costmat[2,2])
total_cost_glm  = -total_profit_glm

# mean profit is the mean 
mean_profit_glm = total_profit_glm/ nrow(validation2) #aggiorna
mean_cost_glm   = -mean_profit_glm #cost expected mean
```

``````{r, echo=FALSE}
#5 modello knn #####

predProb <-  predict(knn, validation2, type = "prob")[,1]
#aggiorna
EP_churn  = (1-predProb)*costmat[2,2] + predProb*costmat[1,2]  
EP_nchurn = predProb*costmat[1,1] + (1-predProb)*costmat[2,1]

decision = ifelse(EP_churn > EP_nchurn, 'True','False')

decision_table = table(validation2$Churn,decision)
decision_table

# total profit of the previous model is sum of profit values weighted by elements of the confusion matrix
total_profit_knn = (decision_table[1,1]*costmat[1,1]+decision_table[2,1]*costmat[2,1]) #aggiorna da fare
total_cost_knn   = -total_profit_knn

# mean profit is the mean 
mean_profit_knn = total_profit_knn/ nrow(validation2) #aggiorna
mean_cost_knn   = -mean_profit_knn #cost expected mean
```

``````{r, echo=FALSE}
#6 modello naivebayes #####

predProb <-  predict(naivebayes,  validation2, type = "prob")[,1]
#aggiorna
EP_churn  = (1-predProb)*costmat[2,2] + predProb*costmat[1,2]  
EP_nchurn = predProb*costmat[1,1] + (1-predProb)*costmat[2,1]

decision = ifelse(EP_churn > EP_nchurn, 'True','False')

decision_table = table(validation2$Churn,decision)
decision_table

# total profit of the previous model is sum of profit values weighted by elements of the confusion matrix
total_profit_naivebayes = (decision_table[1,1]*costmat[1,1]+decision_table[2,1]*costmat[2,1]+decision_table[1,2]*costmat[1,2]+decision_table[2,2]*costmat[2,2])
total_cost_naivebayes   = -total_profit_naivebayes

# mean profit is the mean 
mean_profit_naivebayes = total_profit_naivebayes/ nrow(validation2) #aggiorna
mean_cost_naivebayes   = -mean_profit_naivebayes #cost expected mean
```

``````{r, echo=FALSE}
#7 modello pls #####

predProb <-  predict(pls,  validation2, type = "prob")[,1]
#aggiorna
EP_churn  = (1-predProb)*costmat[2,2] + predProb*costmat[1,2]  
EP_nchurn = predProb*costmat[1,1] + (1-predProb)*costmat[2,1]

decision = ifelse(EP_churn > EP_nchurn, 'True','False')

decision_table = table(validation2$Churn,decision)
decision_table

# total profit of the previous model is sum of profit values weighted by elements of the confusion matrix
total_profit_pls = (decision_table[1,1]*costmat[1,1]+decision_table[2,1]*costmat[2,1])
total_cost_pls   = -total_profit_pls

# mean profit is the mean 
mean_profit_pls = total_profit_pls/ nrow(validation2) #aggiorna
mean_cost_pls   = -mean_profit_pls #cost expected mean
```

``````{r, echo=FALSE}
#8 modello rete #####

predProb <-  predict(nnetFit_CV,  validation3, type = "prob")[,1]
#aggiorna
EP_churn  = (1-predProb)*costmat[2,2] + predProb*costmat[1,2]  
EP_nchurn = predProb*costmat[1,1] + (1-predProb)*costmat[2,1]

decision = ifelse(EP_churn > EP_nchurn, 'True','False')

decision_table = table(validation3$Churn,decision)
decision_table

# total profit of the previous model is sum of profit values weighted by elements of the confusion matrix
total_profit_nnet = (decision_table[1,1]*costmat[1,1]+decision_table[2,1]*costmat[2,1])
total_cost_nnet   = -total_profit_nnet

# mean profit is the mean 
mean_profit_nnet = total_profit_nnet/ nrow(validation3) #aggiorna
mean_cost_nnet   = -mean_profit_nnet #cost expected mean


```



Confronto profitto medio dei modelli: scelgo quello con profitto medio pi√π alto
Profitti medi calcolati (perch√® sono sulla decision table)
```{r}
mean_profit_glm
mean_profit_knn
mean_profit_lasso
mean_profit_model_rf
mean_profit_naivebayes
mean_profit_nnet
mean_profit_pls
mean_profit_tree
```

Vince modello random forest con profitto medio di 8.06


**STEP 3**Evaluation
#######################################################################################
#######################################################################################

Dobbiamo scegliere la soglia che ci garantisca un profitto pi√π alto
``````{r}
#-----------------------------------------------------------------------------
#---------step 3----------------------------------------------------------------------------
# NB the event is True=churn


# prepare data for calculating total costs when varying the threshold
# we want a matrix with: threshold, confusion matrix elements, total costs

result_df <- data.frame(
  threshold      = seq( from = 0.00, to = 1.0, by = 0.01),
  total_exp_profit = rep( 0, 101),
  mean_exp_profit  = rep( 0, 101) 
  )

# for each threshold, calculate total exp costs and mean exp costs#################
# modifica per tot exp profit - cost

predProb_C <- predict(rfTune,  validation, type = "prob")[,2]  # prob di essere predetti come True, cio√® come churn 

y<-ifelse(validation$Churn=='True', 2,1) #y=2 vuol dire True (churn), y=1 False (non churn)


i <- 0
for(threshold in seq(from = 0.00, to = 1.0, by = 0.01)){
  i <- i + 1
  prediction_v <- 1 + as.numeric(predProb_C >= threshold)
  match_count  <- sum(prediction_v == y)
  
  true_negative_count <- sum( prediction_v * y == 1    )        # nb true target 1*predicted 1 = results is 1
  true_positive_count <- sum( prediction_v * y == 4    )        # nb true target 2*predicted 2 = results is 4
  
  false_positive_count <- sum( prediction_v > y        )        #    predicted 2 , true target 1
  false_negative_count <- sum( prediction_v < y        )        #    predicted 1 , true target 2
  
  total_exp_profit <-
    (-100)  * false_positive_count +
    (-5)  * false_negative_count +
    1 * true_positive_count  +
    10 * true_negative_count
  
  mean_exp_profit <- total_exp_profit / nrow(validation)
  
  result_df$mean_exp_profit[i]   <- mean_exp_profit
  result_df$total_exp_profit[i]  <- total_exp_profit
  
}

head(result_df)
```
Questi sono i profitti medi attesi rispetto alle soglie



Grafico: come cambia il profitto medio a seconda della soglia?
``````{r, echo=TRUE, include=TRUE}
# plot cost as function of threshold######

# Questo grafico rappresenta l'andamento del profitto medio atteso rispetto al modificarsi della soglia usata per determinare se un osservazione √® definita come "frode" o meno. Nessuna soglia riesce ad assicurare un profitto quindi andiamo a verificare quale minimizza i costi. Dal grafico si pu√≤ notare come da una certa soglia in poi il costo medio atteso rimane fisso, questo dipende dal fatto che gia' a determinate sognlie, basse, tutti i soggetti vengono classificati come "non frode" quindi in numero di missclassificati non cambia al modificarsi della soglia.

plot(result_df$threshold,result_df$mean_exp_profit)

# Questa √® la soglia che massimizza il profitto atteso, minimizzando i costi. La regola decisionale cos√¨ determinata √® equivalente a quella del EP usata allo step 2.
soglia1 <- result_df[which(result_df$mean_exp_profit == max(result_df$mean_exp_profit)), ]
soglia1
```
stesso profitto atteso con due soglie, scelgo 0.7
```{r}
soglia<-0.7
```


Applico soglia sul validation
```{r}
p_validation = predict(rfTune, validation, "prob")
probc_validation=p_validation[,2] #prob di essere classificato come churn
# applico la regola decisionale utilizzando la soglia dello step 3
pred_validation=ifelse(probc_validation>soglia, "True","False")
table_val <- table(validation$Churn,pred_validation)
table_val

table_val/dim(validation)[1]
```

Profitto totale e medio sul validation con soglia step 3
```{r}
total_profit_val  =  (table_val[1,1]*costmat[1,1]+table_val[1,2]*costmat[1,2]+table_val[2,1]*costmat[2,1]+table_val[2,2]*costmat[2,2])
total_profit_val
mean_profit_val   =  total_profit_val/ nrow(validation)
mean_profit_val
```





**STEP 4**Score
#######################################################################################
#######################################################################################

dataset di score senza colonna del target
```{r}
score1 <- score
score1$Churn <- NULL
dim(score1)
```


Applico la soglia dello step 3 al dataset di score
```{r}
score1$prob = predict(rfTune, score1, "prob")
prob = score1$prob
probc=prob[,2] #prob di essere classificato come churn
# applico la regola decisionale utilizzando la soglia dello step 3
score1$pred1=ifelse(probc>soglia, "True","False")
head(score1$pred1)
```

Incrocio i risultati ottenuti sullo score senza target con lo score da cui sono partito
```{r}
table_mod <- table(score$Churn,score1$pred1)
table_mod

table_mod/dim(score)[1]
```

Profitto totale e profitto medio ottenuti sul dataset di score
```{r}
total_profit_mod  =  (table_mod[1,1]*costmat[1,1]+table_mod[1,2]*costmat[1,2]+table_mod[2,1]*costmat[2,1]+table_mod[2,2]*costmat[2,2])
total_profit_mod
mean_profit_mod   =  total_profit_mod/ nrow(score)
mean_profit_mod
```


SAREI A POSTO, ho massimizzato il profitto totale MA HO UNA CURIOSITA' STATISTICA:
Ho ANCHE buone performance classificative sulle unita' con la decision ottimale dei costi/profitti? 
Vediamo tabella di decisione del validation: 


calcoliamo l'accuracy sul dataset di score per osservare il fit 
table_val(matrice confusione sul validation)
```{r}
table_val 
acc <- (table_val[1,1]+table_val[2,2]) / (table_val[1,1]+table_val[2,2]+table_val[1,2]+table_val[2,1])
acc
```

